<!DOCTYPE html>
<html lang="en-US">
    <head>
        <meta charset="utf-8"> 
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Michael" />
        <meta name="copyright" content="Michael" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", BeautifulSoup, Javascript, Python, Requests, Scraping, Selenium, " />

<meta property="og:title" content="Scraping JavaScript pages with Python: Selenium, Requests, and Beautiful Soup "/>
<meta property="og:url" content="/scraping-javascript-pages-with-python-selenium-requests-and-beautiful-soup.html" />
<meta property="og:description" content="Note: Imgur has an API. Please use the API if you intend to gather images from Imgur. This post is a short demonstration of scraping JavaScript webpages that are not possible to scrape with Beautiful Soup or Requests by themselves. While imgur has an API, the thought occurred that perhaps ..." />
<meta property="og:site_name" content="Caffeine Industries" />
<meta property="og:article:author" content="Michael" />
<meta property="og:article:published_time" content="2015-12-03T23:08:00-07:00" />
<meta name="twitter:title" content="Scraping JavaScript pages with Python: Selenium, Requests, and Beautiful Soup ">
<meta name="twitter:description" content="Note: Imgur has an API. Please use the API if you intend to gather images from Imgur. This post is a short demonstration of scraping JavaScript webpages that are not possible to scrape with Beautiful Soup or Requests by themselves. While imgur has an API, the thought occurred that perhaps ...">

        <title>Scraping JavaScript pages with Python: Selenium, Requests, and Beautiful Soup  · Caffeine Industries
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.1/css/font-awesome.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="/theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css" href="/theme/tipuesearch/tipuesearch.css" media="screen">
        <link rel="stylesheet" type="text/css" href="/theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css" href="/theme/css/custom.css" media="screen">
    </head>
    <body>
        <div id="content-sans-footer">
        <div class="navbar navbar-static-top">
            <div class="navbar-inner">
                <div class="container-fluid">
                    <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </a>
                    <a class="brand" href="/"><span class=site-name>Caffeine Industries</span></a>
                    <div class="nav-collapse collapse">
                        <ul class="nav pull-right top-menu">
                            <li ><a href="">Home</a></li>
                            <li ><a href="/categories.html">Categories</a></li>
                            <li ><a href="/tags.html">Tags</a></li>
                            <li ><a href="/archives.html">Archives</a></li>
                            <li><form class="navbar-search" action="/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row-fluid">
                <div class="span1"></div>
                <div class="span10">
<article>
<div class="row-fluid">
    <header class="page-header span10 offset2">
    <h1><a href="/scraping-javascript-pages-with-python-selenium-requests-and-beautiful-soup.html"> Scraping JavaScript pages with Python: Selenium, Requests, and Beautiful Soup  </a></h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">

            
            <p><strong>Note: Imgur has an API. Please use the API if you intend to gather
images from Imgur.</strong></p>
<p>This post is a short demonstration of scraping JavaScript webpages that
are not possible to scrape with <a href="http://www.crummy.com/software/BeautifulSoup/">Beautiful
Soup</a> or
<a href="http://docs.python-requests.org/en/latest/">Requests</a> by themselves.
 While imgur has an API, the thought occurred that perhaps there are
many, many sites that do not have an API that need a good scraping. If
that is the case, how do you scrape them?
<a href="http://selenium-python.readthedocs.org/installation.html">Selenium</a>.
Lets dive in and I will show you:</p>
<p>First things first, import the modules that will be used. You will need
to install these I prefer to use the
<a href="https://www.continuum.io/downloads">Anaconda</a> Python distribution. The
managing of Python environments is not in the scope of this demo, so I
will leave the management of that to you. Suffice to say that you can
install requests and beautiful soup with conda. Selenium can be created
as a package then uploaded to Anaconda Cloud with Binstar and... well,
you can simply install Selenium with pip.</p>
<p>``` {.lang:python .decode:true}
import os
from selenium import webdriver
from bs4 import BeautifulSoup
from requests import get</p>
<div class="highlight"><pre>\[line\]  
Next, define where you want to store the images. This will store the
image in the present working directory or the directory where the script
lives.

``` {.lang:python .decode:true}
# Make a directory in the pwd, if one already exists. Cool.
os.makedirs(&#39;imgur&#39;, exist_ok=True) # Make directory to store the images
</pre></div>


<p>[line]<br />
Now we can instantiate the Selenium webdriver, and pass a url to fetch.
I used firefox because it seems like it is very well supported. I didn't
even try with Chrome which is my browser of choice.</p>
<p>``` {.lang:python .decode:true}</p>
<h1>Imgur is not possible to scrape without Selenium. Because Javascript.</h1>
<p>browser = webdriver.Firefox() # Instantiate a webdriver object
browser.get('http://imgur.com') # Go to Imgur</p>
<div class="highlight"><pre>\[<span class="n">line</span>\]  
<span class="n">This</span> <span class="k">is</span> <span class="k">where</span> <span class="n">your</span> <span class="n">investigation</span> <span class="n">begins</span>. <span class="n">First</span>, <span class="n">define</span> <span class="n">an</span> <span class="n">empty</span> <span class="n">list</span> <span class="nb">to</span>
<span class="n">hold</span> <span class="n">the</span> <span class="n">links</span> <span class="k">of</span> <span class="n">the</span> <span class="n">pages</span>. <span class="n">Turns</span> <span class="n">out</span> <span class="n">that</span> <span class="n">imgur</span> <span class="n">renders</span> <span class="n">the</span> <span class="n">home</span> <span class="n">page</span>
<span class="n">with</span> <span class="n">thumbnails</span> <span class="k">of</span> <span class="n">images</span>. <span class="n">The</span> <span class="n">links</span> <span class="nb">to</span> <span class="n">the</span> <span class="n">pages</span> <span class="k">where</span> <span class="n">the</span> <span class="n">main</span> <span class="n">image</span>
<span class="n">src</span> <span class="n">resides</span> <span class="k">is</span> <span class="n">within</span> <span class="n">the</span> <span class="k">class</span> <span class="n">image-list-link</span>. <span class="n">Every</span> <span class="n">website</span> <span class="k">is</span>
<span class="n">different</span> <span class="o">and</span> <span class="n">rendered</span> <span class="n">JavaScript</span> <span class="n">pages</span> <span class="nb">can</span> <span class="k">use</span> <span class="n">wildly</span> <span class="n">different</span> <span class="n">naming</span>
<span class="n">conventions</span>. <span class="n">Thus</span> <span class="n">the</span> <span class="n">need</span> <span class="nb">to</span> <span class="n">dig</span> <span class="n">with</span> <span class="n">your</span> <span class="n">browser</span> <span class="o">before</span> <span class="n">you</span> <span class="n">start</span>
<span class="n">coding</span>.  <span class="n">To</span> <span class="n">investigate</span> <span class="n">with</span> <span class="n">a</span> <span class="n">OSX</span>, <span class="n">tune</span> <span class="n">your</span> <span class="n">browser</span> (<span class="n">chrome</span>) <span class="nb">to</span> <span class="n">the</span>
<span class="n">url</span> <span class="n">you</span> <span class="n">wish</span> <span class="nb">to</span> <span class="n">scrape</span> <span class="o">and</span> <span class="n">press:</span> <span class="n">option</span> | <span class="n">command</span> | <span class="n">j</span>  <span class="n">Then</span> <span class="n">start</span>
<span class="n">inspecting</span> <span class="n">elements</span>.

``` {.<span class="n">lang:python</span> .<span class="n">decode:true</span>}
<span class="c-Singleline"># Makes list of links to get full image</span>
<span class="n">links</span> = []
<span class="c-Singleline"># This is the container of images on the main page</span>
<span class="n">cards</span> = <span class="n">browser</span>.<span class="n">find_elements_by_class_name</span>(<span class="s">&#39;image-list-link&#39;</span>)
<span class="k">for</span> <span class="n">img_src</span> <span class="n">in</span> <span class="n">cards:</span>
    <span class="c-Singleline"># Now assemble list to pass to requests and beautifulsoup</span>
    <span class="n">links</span>.<span class="n">append</span>(<span class="n">img_src</span>.<span class="n">get_attribute</span>(<span class="s">&#39;href&#39;</span>))
</pre></div>


<p>[line]<br />
The rest of the story. This bit of code loops through the links list
created in the previous snippet. We call requests.get() to url stored in
links list. Then we pass the html from requests to beautiful soup where
we can dominate it with reckless abandon. We ask soup to select the
post-image class img tag. Then we check if it is empty. If the list is
not empty, we assign the actual src of the imageLink to imageUrl. This
variable is prefixed with http: and sent back to requests for retrieval.
 If the url is mangled or mistyped we handle the exception and move to
the next one. If not, we write the file to directory and using requests
iter_chunks method in 100,000 byte increments. Close the image file and
start the next round or finish the script.</p>
<p>``` {.lang:python .decode:true}</p>
<h1>loop through the links list (I'm slicing to 5)</h1>
<p>for page in links[:5]:
    res = requests.get(page)
    res.raise_for_status()
    soup = BeautifulSoup(res.text, 'html.parser')
    imageLink = soup.select('.post-image img')
    if imageLink == []:
        print('Nothing here...')
    else:
        try:
            # assign imageUrl hold the actual file name of the image
            imageUrl = imageLink[0].get('src')
            #Download the image
            print('Downloading image %s...' %(imageUrl))
            res = requests.get('http:'+imageUrl)
            res.raise_for_status()
        except requests.exceptions.MissingSchema:
            continue
        imageFile = open(os.path.join('imgur', os.path.basename(imageUrl)), 'wb')
        for chunk in res.iter_content(100000):
            imageFile.write(chunk)
        imageFile.close()
```</p>
            
            
            <hr/>
        </div>
        <section>
        <div class="span2" style="float:right;font-size:0.9em;">
            <h4>Published</h4>
            <time pubdate="pubdate" datetime="2015-12-03T23:08:00-07:00">Dec 3, 2015</time>
            <h4>Category</h4>
            <a class="category-link" href="/categories.html#beautifulsoup-javascript-python-requests-scraping-selenium-ref">BeautifulSoup, Javascript, Python, Requests, Scraping, Selenium</a>
<h4>Contact</h4>
    <a href="#" title="My You can add links in your config file Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-you can add links in your config file sidebar-social-links"></i></a>
    <a href="#" title="My Another social link Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-another social link sidebar-social-links"></i></a>
        </div>
        </section>
</div>
</article>
                </div>
                <div class="span1"></div>
            </div>
        </div>
        <div id="push"></div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="http://oncrashreboot.com/pelican-elegant" title="Theme Elegant Home Page">Elegant</a> by <a href="http://oncrashreboot.com" title="Talha Mansoor Home Page">Talha Mansoor</a></li>
    </ul>
</div>
</footer>            <script src="http://code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    
    </body>
    <!-- Theme: Elegant built for Pelican
    License : http://oncrashreboot.com/pelican-elegant -->
</html>